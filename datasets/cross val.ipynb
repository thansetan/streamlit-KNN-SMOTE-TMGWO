{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "import functools\n",
    "from tabulate import tabulate\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, accuracy_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from TMGWO import TMGWO\n",
    "\n",
    "\n",
    "def load_dataset(dataset):\n",
    "    data = pd.read_csv(dataset)\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess(data):\n",
    "    objectList = data.select_dtypes(include=\"object\").columns\n",
    "    intList = data.select_dtypes(include=\"int64\").columns\n",
    "    le = LabelEncoder()\n",
    "    scaler = MinMaxScaler()\n",
    "    for feature in objectList:\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "    for feature in intList:\n",
    "        data[[feature]] = scaler.fit_transform(data[[feature]])\n",
    "    # joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_preprocessed(preprocessed):\n",
    "    preprocessed.to_csv(\"datasets/diabetes_preprocessed.csv\", index=False)\n",
    "\n",
    "\n",
    "def split_preprocessed(preprocessed):\n",
    "    X = preprocessed[preprocessed.columns[:-1]].values\n",
    "    y = preprocessed[preprocessed.columns[-1]].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=42, test_size=0.2, shuffle=True, stratify=y\n",
    "    )\n",
    "    return X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def split_for_crossval(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=42, test_size=0.2, shuffle=True, stratify=y\n",
    "    )\n",
    "    return X_train,y_train\n",
    "\n",
    "\n",
    "def fitness(x, X_train, y_train, X_test, y_test):\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(1, -1)\n",
    "    loss = np.zeros(x.shape[0])\n",
    "    model = KNeighborsClassifier(metric=\"jaccard\", n_neighbors=2)\n",
    "    for i in range(x.shape[0]):\n",
    "        if np.sum(x[i, :]) > 0:\n",
    "            model.fit(X_train[:, x[i, :].astype(bool)], y_train)\n",
    "            score = accuracy_score(\n",
    "                model.predict(X_test[:, x[i, :].astype(bool)]), y_test\n",
    "            )\n",
    "            loss[i] = 0.99 * (1 - score) + 0.01 * (np.sum(x[i, :]) / X_train.shape[1])\n",
    "        else:\n",
    "            loss[i] = np.inf\n",
    "    return loss\n",
    "\n",
    "\n",
    "def data_antar_kelas(y_train):\n",
    "    positive = list(y_train).count(1)\n",
    "    negative = list(y_train).count(0)\n",
    "    fig = plt.figure()\n",
    "    plt.title(\"Data antar kelas pada training data\")\n",
    "    plt.bar(\"Positive\", positive)\n",
    "    plt.annotate(positive, (0, positive / 2), ha=\"center\")\n",
    "    plt.bar(\"Negative\", negative)\n",
    "    plt.annotate(negative, (1, negative / 2), ha=\"center\")\n",
    "    plt.xlabel(\"Kelas\")\n",
    "    plt.ylabel(\"Jumlah data\")\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def feature_selection(X_train, X_test, y_train, y_test):\n",
    "    lossfunc = functools.partial(\n",
    "        fitness, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test\n",
    "    )\n",
    "    optimizer = TMGWO(fitness=lossfunc, D=X_train.shape[1], P=8, G=70)\n",
    "    optimizer.optimize()\n",
    "    selected_features = optimizer.gBest_X > 0\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def plot_selected_features(X, selected_features):\n",
    "    fig = plt.figure()\n",
    "    plt.title(\"Jumlah Fitur Sebelum dan Sesudah Seleksi Fitur\")\n",
    "    plt.bar(\"before\", X.shape[1])\n",
    "    plt.annotate(X.shape[1], (0, X.shape[1] / 2), ha=\"center\")\n",
    "    plt.bar(\"after\", X[:, selected_features].shape[1])\n",
    "    plt.annotate(\n",
    "        X[:, selected_features].shape[1],\n",
    "        (1, X[:, selected_features].shape[1] / 2),\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    plt.ylabel(\"Num of features\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def do_smote(X_train, y_train):\n",
    "    smote = SMOTENC(\n",
    "        random_state=42,\n",
    "        categorical_features=[\n",
    "            False,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "        ],\n",
    "    )\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_smote, y_train_smote\n",
    "\n",
    "\n",
    "def plot_smote(y_train_smote):\n",
    "    positive = list(y_train_smote).count(1)\n",
    "    negative = list(y_train_smote).count(0)\n",
    "    fig = plt.figure()\n",
    "    plt.title(\"Data antar kelas pada training data setelah SMOTE\")\n",
    "    plt.bar(\"Positive\", height=positive)\n",
    "    plt.annotate(positive, (0, positive / 2), ha=\"center\", fontsize=20)\n",
    "    plt.bar(\"Negative\", height=negative)\n",
    "    plt.annotate(negative, (1, negative / 2), ha=\"center\", fontsize=20)\n",
    "    plt.xlabel(\"Kelas\")\n",
    "    plt.ylabel(\"Jumlah data\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "hasil = {}\n",
    "hasil[\"cross_val\"] = {}\n",
    "hasil[\"cross_val\"][\"num_sf\"] = []\n",
    "hasil[\"cross_val\"][\"akurasi\"] = {}\n",
    "hasil[\"cross_val\"][\"cm\"] = {}\n",
    "hasil[\"cross_val\"][\"cr\"] = {}\n",
    "hasil[\"akurasi\"] = {}\n",
    "hasil[\"cm\"] = {}\n",
    "hasil[\"cr\"] = {}\n",
    "\n",
    "\n",
    "def cross_val_knn(X, y):\n",
    "    X_train, y_train = split_for_crossval(X, y)\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in sss.split(X_train, y_train):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = KNeighborsClassifier(metric=\"jaccard\", n_neighbors=5)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        hasil[\"cross_val\"][\"akurasi\"][\"KNN\"].append(\n",
    "            float(\"{:.2f}\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "        )\n",
    "        hasil[\"cross_val\"][\"cm\"][\"KNN\"].append(confusion_matrix(y_test, y_pred))\n",
    "        hasil[\"cross_val\"][\"cr\"][\"KNN\"].append(\n",
    "            classification_report(\n",
    "                y_test, y_pred, output_dict=True, target_names=[\"Negative\", \"Positive\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def cross_val_knn_smote(X, y):\n",
    "    X_train, y_train = split_for_crossval(X, y)\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in sss.split(X_train, y_train):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        smote = SMOTENC(\n",
    "            random_state=42,\n",
    "            categorical_features=[\n",
    "                False,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "            ],\n",
    "        )\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        model = KNeighborsClassifier(metric=\"jaccard\", n_neighbors=5)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        hasil[\"cross_val\"][\"akurasi\"][\"KNN+SMOTE\"].append(\n",
    "            float(\"{:.2f}\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "        )\n",
    "        hasil[\"cross_val\"][\"cm\"][\"KNN+SMOTE\"].append(confusion_matrix(y_test, y_pred))\n",
    "        hasil[\"cross_val\"][\"cr\"][\"KNN+SMOTE\"].append(\n",
    "            classification_report(\n",
    "                y_test, y_pred, output_dict=True, target_names=[\"Negative\", \"Positive\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def cross_val_knn_smote_tmgwo(X, y):\n",
    "    X_train, y_train = split_for_crossval(X, y)\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in sss.split(X_train, y_train):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        smote = SMOTENC(\n",
    "            random_state=42,\n",
    "            categorical_features=[\n",
    "                False,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "            ],\n",
    "        )\n",
    "        selected_features = feature_selection(X_train, X_test, y_train, y_test)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        model = KNeighborsClassifier(metric=\"jaccard\", n_neighbors=5)\n",
    "        model.fit(X_train[:, selected_features], y_train)\n",
    "        y_pred = model.predict(X_test[:, selected_features])\n",
    "        hasil[\"cross_val\"][\"akurasi\"][\"KNN+SMOTE+TMGWO\"].append(\n",
    "            float(\"{:.2f}\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "        )\n",
    "        hasil[\"cross_val\"][\"cm\"][\"KNN+SMOTE+TMGWO\"].append(\n",
    "            confusion_matrix(y_test, y_pred)\n",
    "        )\n",
    "        hasil[\"cross_val\"][\"cr\"][\"KNN+SMOTE+TMGWO\"].append(\n",
    "            classification_report(\n",
    "                y_test, y_pred, output_dict=True, target_names=[\"Negative\", \"Positive\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    X, y, X_train, X_test, y_train, y_test, algoritma, selected_features=None\n",
    "):\n",
    "    hasil[\"cross_val\"][\"akurasi\"][algoritma] = []\n",
    "    hasil[\"cross_val\"][\"cm\"][algoritma] = []\n",
    "    hasil[\"cross_val\"][\"cr\"][algoritma] = []\n",
    "    if algoritma == \"KNN\":\n",
    "        cross_val_knn(X, y)\n",
    "    if algoritma == \"KNN+SMOTE\":\n",
    "        cross_val_knn_smote(X, y)\n",
    "    if algoritma == \"KNN+SMOTE+TMGWO\":\n",
    "        cross_val_knn_smote_tmgwo(X, y)\n",
    "    model = KNeighborsClassifier(metric=\"jaccard\", n_neighbors=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    # if algoritma == \"KNN+SMOTE+TMGWO\":\n",
    "    #     y_pred = model.predict(X_test[:, selected_features])\n",
    "    # else:\n",
    "    y_pred = model.predict(X_test)\n",
    "    hasil[\"akurasi\"][algoritma] = float(\n",
    "        \"{:.2f}\".format(accuracy_score(y_test, y_pred) * 100)\n",
    "    )\n",
    "    hasil[\"cm\"][algoritma] = confusion_matrix(y_test, y_pred)\n",
    "    hasil[\"cr\"][algoritma] = classification_report(\n",
    "        y_test, y_pred, output_dict=True, target_names=[\"Negative\", \"Positive\"]\n",
    "    )\n",
    "    score = hasil[\"akurasi\"][algoritma]\n",
    "    cm = hasil[\"cm\"][algoritma]\n",
    "    cr = hasil[\"cr\"][algoritma]\n",
    "    joblib.dump(model, f\"models/{algoritma}.pkl\")\n",
    "    return model, score, cm, cr\n",
    "\n",
    "\n",
    "def get_highest_acc_index(hasil):\n",
    "    index = {}\n",
    "    for key, val in hasil[\"akurasi\"].items():\n",
    "        index[key] = val.index(max(val))\n",
    "    return index\n",
    "\n",
    "\n",
    "def plot_cm(cm, algo):\n",
    "    fig, ax = plt.subplots()\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "    cm.plot(ax=ax)\n",
    "    plt.title(f\"Confusion Matrix {algo}\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_highest_accuracy(hasil):\n",
    "    fig = plt.figure()\n",
    "    acc = [acc for acc in hasil[\"akurasi\"].values()]\n",
    "    label = [algoritma for algoritma in hasil[\"akurasi\"].keys()]\n",
    "    juml = len(acc)\n",
    "    plt.title(\"Hasil Model\")\n",
    "    for i in range(juml):\n",
    "        plt.bar(i, acc[i], label=\"Ori\")\n",
    "        plt.annotate(f\"{acc[i]} %\", (i, acc[i] / 2), ha=\"center\")\n",
    "    plt.ylabel(\"Akurasi\")\n",
    "    plt.xticks([i for i in range(juml)], label)\n",
    "    plt.xlabel(\"Algoritma\")\n",
    "    plt.ylim(0, 100)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = split_preprocessed(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algoritma in [\"KNN\", \"KNN+SMOTE\", \"KNN+SMOTE+TMGWO\"]:\n",
    "    hasil[\"cross_val\"][\"akurasi\"][algoritma] = []\n",
    "    hasil[\"cross_val\"][\"cr\"][algoritma] = []\n",
    "    hasil[\"cross_val\"][\"cm\"][algoritma] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_knn(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_knn_smote(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil[\"cross_val\"][\"akurasi\"][\"KNN+SMOTE+TMGWO\"] = []\n",
    "hasil[\"cross_val\"][\"cm\"][\"KNN+SMOTE+TMGWO\"] = []\n",
    "hasil[\"cross_val\"][\"cr\"][\"KNN+SMOTE+TMGWO\"] = []\n",
    "hasil['cross_val']['num_sf'] = []\n",
    "X_train, y_train = split_for_crossval(X, y)\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "for train, test in sss.split(X_train, y_train):\n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    smote = SMOTENC(\n",
    "            random_state=42,\n",
    "            categorical_features=[\n",
    "                False,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "                True,\n",
    "            ],\n",
    "        )\n",
    "    selected_features = feature_selection(X_train, X_test, y_train, y_test)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    model = KNeighborsClassifier(metric='jaccard', n_neighbors=5)\n",
    "    model.fit(X_train[:, selected_features], y_train)\n",
    "    y_pred = model.predict(X_test[:, selected_features])\n",
    "    hasil[\"cross_val\"][\"akurasi\"][\"KNN+SMOTE+TMGWO\"].append(\n",
    "            float(\"{:.2f}\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "        )\n",
    "    hasil[\"cross_val\"][\"cm\"][\"KNN+SMOTE+TMGWO\"].append(\n",
    "            confusion_matrix(y_test, y_pred)\n",
    "        )\n",
    "    hasil[\"cross_val\"][\"cr\"][\"KNN+SMOTE+TMGWO\"].append(\n",
    "            classification_report(\n",
    "                y_test, y_pred, output_dict=True, target_names=[\"Negative\", \"Positive\"]\n",
    "            )\n",
    "        )\n",
    "    hasil['cross_val']['num_sf'].append(list(selected_features).count(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================KNN==================================\n",
      "    1      2      3      4      5      6      7      8      9     10\n",
      "-----  -----  -----  -----  -----  -----  -----  -----  -----  -----\n",
      "90.48  91.67  92.86  90.48  94.05  96.43  90.48  95.24  89.29  91.67\n",
      "\n",
      "rata-rata:  92.265\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "==============================KNN+SMOTE===============================\n",
      "   1      2      3      4      5      6     7      8      9     10\n",
      "----  -----  -----  -----  -----  -----  ----  -----  -----  -----\n",
      "88.1  90.48  96.43  90.48  94.05  96.43  86.9  94.05  89.29  89.29\n",
      "\n",
      "rata-rata:  91.55\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "===========================KNN+SMOTE+TMGWO============================\n",
      "    1      2      3      4      5      6      7      8      9     10\n",
      "-----  -----  -----  -----  -----  -----  -----  -----  -----  -----\n",
      "91.67  95.24  96.43  95.24  98.81  95.24  92.86  94.05  94.05  91.67\n",
      "\n",
      "rata-rata:  94.526\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "for key, val in hasil['cross_val']['akurasi'].items():\n",
    "    print(key.center(70, '='))\n",
    "    print(tabulate([val], headers=[str(i) for i in range(1,11)]))\n",
    "    print()\n",
    "    print(\"rata-rata: \", np.mean(val))\n",
    "    print(\"+\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junlah fitur pada tiap fold\n",
      "  1    2    3    4    5    6    7    8    9    10\n",
      "---  ---  ---  ---  ---  ---  ---  ---  ---  ----\n",
      "  8   12   10   11   10    9   12   10   12    12\n"
     ]
    }
   ],
   "source": [
    "print(\"junlah fitur pada tiap fold\")\n",
    "print(tabulate([hasil['cross_val']['num_sf']], headers=[str(i) for i in range(1,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(hasil['cross_val']['akurasi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sf = pd.DataFrame(hasil['cross_val']['num_sf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"hasil_cross_val_akurasi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sf.to_csv(\"hasil_cross_val_num_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('skripsi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0179599969af96929fefc49d6a1f04169f527ccdb362c5b7a291fcf3c4d840c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
